{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4ca49-97b3-48d7-aba1-f280bcbb6c42",
   "metadata": {},
   "source": [
    "## Fetch 2009 PhysioNet challenge data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c6cc1-a792-4d9c-a5ad-427e82100ca9",
   "metadata": {},
   "source": [
    "https://archive.physionet.org/challenge/2009/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f1f80-7b98-4c7c-8bdc-6a1f30a0e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tarfile\n",
    "import wfdb\n",
    "\n",
    "from src.data.parsing import parse_txt\n",
    "\n",
    "source_url = 'https://archive.physionet.org/challenge/2009/training-set-clinical-data.tar.gz'\n",
    "target_dir = 'data'\n",
    "target_path = f'{target_dir}/training-set-clinical-data.tar.gz'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf2d6b-96a4-4a0d-90aa-f1ca6d717042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_settings():\n",
    "    return {\n",
    "        'fetch_clinical_data': False,\n",
    "        'verbose': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de98a68-d95c-4fc1-8705-2510c65e999f",
   "metadata": {},
   "source": [
    "## Fetch archive of PhysioNet challenge records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5e819-a651-4605-a620-31767082205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fetch_settings()['fetch_clinical_data']:\n",
    "    response = requests.get(source_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(target_path, 'wb') as f:\n",
    "            f.write(response.raw.read())\n",
    "\n",
    "    with tarfile.open(target_path, \"r:gz\") as tar_file:\n",
    "        tar_file.extractall(target_dir)\n",
    "else: \n",
    "    print(\"Use cached clinical data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71eefb8-46d7-4bef-9b0b-a1d70ec5992e",
   "metadata": {},
   "source": [
    "## Handle individual records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455e75d-2661-4ad2-9929-d2da97aca3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_map = pd.read_csv(\n",
    "    'data/mimic2cdb/MAP', \n",
    "    sep=\"\\t\", \n",
    "    names = ['Clinical', 'Wave', 'Sex', 'Age', 'Birthdate', 'Waveform'],\n",
    "    index_col = False, \n",
    "    skiprows = [0,1])\n",
    "record_map.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310d664-13a7-4532-9b17-32ca7512a388",
   "metadata": {},
   "source": [
    "## Functions to generate waveform data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ea9a3-491c-4531-ae93-f2155f29fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_record_map():\n",
    "    settings = fetch_settings()\n",
    "    df = pd.read_csv(\n",
    "        'data/mimic2cdb/MAP', \n",
    "        sep=\"\\t\", \n",
    "        names = ['Clinical', 'Wave', 'Sex', 'Age', 'Birthdate', 'Waveform'],\n",
    "        index_col = False, \n",
    "        skiprows = [0,1])\n",
    "    if settings['verbose']:\n",
    "        print(f\"Dimensions of data set: {df.shape}\")\n",
    "        print(f\"Data set reflects data for {len(df['Clinical'].unique().tolist())} clinical IDs\")\n",
    "        print(f\"Data set reflects data for {len(df['Wave'].unique().tolist())} waveform IDs\")\n",
    "    return({'data':df, \n",
    "            'clinical_entities': df['Clinical'].unique().tolist(),\n",
    "            'waveform_entities': df['Wave'].unique().tolist()\n",
    "           })\n",
    "\n",
    "\n",
    "def filter_data_to_entity(df, entity_colname, entity):\n",
    "    return df[df[entity_colname] == entity]\n",
    "\n",
    "\n",
    "def generate_waveform_dataset(e, df):\n",
    "    settings = fetch_settings()\n",
    "    data = filter_data_to_entity(df, 'Wave', e)\n",
    "    data = data.squeeze().to_dict()\n",
    "    if settings['verbose']: print(data)\n",
    "    record = wfdb.rdrecord(f\"data/train_wave/{data['Wave']}\")\n",
    "    return {\n",
    "        'raw_data': data,\n",
    "        'waveform_data': record\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff903b-78ac-426c-a6b1-307277b37b70",
   "metadata": {},
   "source": [
    "## Generate the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991b147-5129-454d-89d5-4a35d2cea3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_map = generate_record_map()\n",
    "x = {e:generate_waveform_dataset(e, record_map['data']) for e in record_map['waveform_entities'][0:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6fb10-147f-4e1c-86a3-3ed33c65bcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
