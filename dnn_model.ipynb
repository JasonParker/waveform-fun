{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6039a-8d75-4a6d-90b5-cccf3d6e6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e6101-2be2-40f3-8eb6-04b083a73e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECT_ID="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3f163-731e-42b3-82a9-17fd3b64dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(project=os.environ['PROJECT_ID'])\n",
    "bucket_name = 'physionet_2009'\n",
    "fs.ls(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba5305-a890-40d4-b09a-fbe3960e4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "NUM_TRAIN_EXAMPLES = 256871  # training dataset repeats, it'll wrap around\n",
    "NUM_EVALS = 5  # how many times to evaluate\n",
    "# Enough to get a reasonable sample, but not so much that it slows down\n",
    "NUM_EVAL_EXAMPLES = 64218\n",
    "\n",
    "CSV_COLUMNS = ['wave', 'start_window', 'end_window', 'avg_sys', 'avg_dias', 'avg_map',\n",
    "       'current_hypotensive', 'hypotensive_in_15']\n",
    "DEFAULTS = [[''],[0.0],[0.0],[0.0],[0.0],[0.0],\n",
    "            [0.0],[0.0]]\n",
    "\n",
    "LABEL_COLUMN = 'hypotensive_in_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07f79f-ddc3-48d8-b590-3b6318553fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = get_training_labels()\n",
    "training_data = pd.read_csv(fs.open(f'{bucket_name}/processed/processed_all.csv'))\n",
    "\n",
    "training_data.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'], inplace = True)\n",
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dff61e-0d94-43f3-ac25-4fbfdfc1e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316f333-52bc-4063-bd05-9d53b5812412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_labels(row_data):\n",
    "    \"\"\"Splits features and labels from feature dictionary.\n",
    "\n",
    "    Args:\n",
    "        row_data: Dictionary of CSV column names and tensor values.\n",
    "    Returns:\n",
    "        Dictionary of feature tensors and label tensor.\n",
    "    \"\"\"\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "\n",
    "    return row_data, label  # features, label\n",
    "\n",
    "\n",
    "def load_dataset(pattern,csv_columns,defaults,label_column, batch_size=1, mode=tf.estimator.ModeKeys.EVAL):\n",
    "    \"\"\"Loads dataset using the tf.data API from CSV files.\n",
    "\n",
    "    Args:\n",
    "        pattern: str, file pattern to glob into list of files.\n",
    "        batch_size: int, the number of examples per batch.\n",
    "        mode: tf.estimator.ModeKeys to determine if training or evaluating.\n",
    "    Returns:\n",
    "        `Dataset` object.\n",
    "    \"\"\"\n",
    "    # Make a CSV dataset\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=pattern,\n",
    "        batch_size=batch_size,\n",
    "        column_names=csv_columns,\n",
    "        column_defaults=defaults)\n",
    "    print(type(dataset))\n",
    "\n",
    "    # Map dataset to features and label\n",
    "    dataset = dataset.map(map_func=features_and_labels)  # features, label\n",
    "    \n",
    "    # Shuffle and repeat for training\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # Take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fef669-9ff8-47e6-9c3e-b6652f136e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(pattern = 'data/training_data_cleaned.csv',\n",
    "                        csv_columns = CSV_COLUMNS,\n",
    "                        defaults = DEFAULTS,\n",
    "                        label_column = LABEL_COLUMN,\n",
    "                        batch_size=TRAIN_BATCH_SIZE,\n",
    "                        mode=tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "\n",
    "\n",
    "test_df = load_dataset(pattern = 'data/test_data_cleaned.csv',\n",
    "                        csv_columns = CSV_COLUMNS,\n",
    "                        defaults = DEFAULTS,\n",
    "                        label_column = LABEL_COLUMN,\n",
    "                        batch_size=TRAIN_BATCH_SIZE,\n",
    "                        mode=tf.estimator.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9a6ca-a599-40bb-b503-4c910723e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205a2f6-8552-4226-a2f3-d6340d00e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0f277-8d21-428c-8143-4a7ec1ed08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_layers():\n",
    "    \"\"\"Creates dictionary of input layers for each feature.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of `tf.Keras.layers.Input` layers for each feature.\n",
    "    \"\"\"\n",
    "    inputs = {\n",
    "        colname: tf.keras.layers.Input(\n",
    "            name=colname, shape=(), dtype=\"float32\")\n",
    "        for colname in [\"avg_sys\", \"avg_dias\", \"current_hypotensive\"]}\n",
    "    '''\n",
    "    inputs.update({\n",
    "        colname: tf.keras.layers.Input(\n",
    "            name=colname, shape=(), dtype=\"string\")\n",
    "        for colname in [\"is_male\", \"plurality\"]})\n",
    "    '''\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed096c-efa2-4148-8372-337988d55447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23235e-8913-4231-93bc-3fb9395f44f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ab111-ebe2-4053-a2ae-b338e872ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a905f-1a71-4a23-a8d6-154a7e15050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_fc(name, values):\n",
    "    \"\"\"Helper function to wrap categorical feature by indicator column.\n",
    "\n",
    "    Args:\n",
    "        name: str, name of feature.\n",
    "        values: list, list of strings of categorical values.\n",
    "    Returns:\n",
    "        Indicator column of categorical feature.\n",
    "    \"\"\"\n",
    "    cat_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=name, vocabulary_list=values)\n",
    "\n",
    "    return tf.feature_column.indicator_column(categorical_column=cat_column)\n",
    "\n",
    "\n",
    "def create_feature_columns():\n",
    "    \"\"\"Creates dictionary of feature columns from inputs.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of feature columns.\n",
    "    \"\"\"\n",
    "    feature_columns = {\n",
    "        colname : tf.feature_column.numeric_column(key=colname)\n",
    "           for colname in [\"avg_sys\", \"avg_dias\", \"current_hypotensive\"]\n",
    "    }\n",
    "    '''\n",
    "    feature_columns[\"is_male\"] = categorical_fc(\n",
    "        \"is_male\", [\"True\", \"False\", \"Unknown\"])\n",
    "    feature_columns[\"plurality\"] = categorical_fc(\n",
    "        \"plurality\", [\"Single(1)\", \"Twins(2)\", \"Triplets(3)\",\n",
    "                      \"Quadruplets(4)\", \"Quintuplets(5)\", \"Multiple(2+)\"])\n",
    "    '''\n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e576cc-7cbb-449d-a114-60b794351320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc805f-d995-4237-97e0-c19ecd3aa8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2206a99-b44b-46f9-ba0f-0b62d92bbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hidden and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d2f49-22e9-426e-a351-5b30efd69a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_outputs(inputs):\n",
    "    \"\"\"Creates model architecture and returns outputs.\n",
    "\n",
    "    Args:\n",
    "        inputs: Dense tensor used as inputs to model.\n",
    "    Returns:\n",
    "        Dense tensor output from the model.\n",
    "    \"\"\"\n",
    "    # Create two hidden layers of [64, 32] just in like the BQML DNN\n",
    "    h1 = tf.keras.layers.Dense(64, activation=\"relu\", name=\"h1\")(inputs)\n",
    "    h2 = tf.keras.layers.Dense(32, activation=\"relu\", name=\"h2\")(h1)\n",
    "\n",
    "    # Final output is a linear activation because this is regression\n",
    "    output = tf.keras.layers.Dense(\n",
    "        units=1, activation=\"sigmoid\", name=\"weight\")(h2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71725215-f59c-4751-94b7-03437c2e0ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4f681-a2a3-4bdb-bd3e-5243ff885500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1c7ae-b3ff-4a95-a7ed-482b66601697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25c6d5-e38a-4b36-9877-fabf02cd34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64248c3-cbfb-44d2-b9aa-21a7a695ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_model():\n",
    "    \"\"\"Builds simple DNN using Keras Functional API.\n",
    "\n",
    "    Returns:\n",
    "        `tf.keras.models.Model` object.\n",
    "    \"\"\"\n",
    "    # Create input layer\n",
    "    inputs = create_input_layers()\n",
    "\n",
    "    # Create feature columns\n",
    "    feature_columns = create_feature_columns()\n",
    "\n",
    "    # The constructor for DenseFeatures takes a list of numeric columns\n",
    "    # The Functional API in Keras requires: LayerConstructor()(inputs)\n",
    "    dnn_inputs = tf.keras.layers.DenseFeatures(\n",
    "        feature_columns=feature_columns.values())(inputs)\n",
    "\n",
    "    # Get output of model given inputs\n",
    "    output = get_model_outputs(dnn_inputs)\n",
    "\n",
    "    # Build model and compile it all together\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['AUC','Precision','Recall'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Here is our DNN architecture so far:\\n\")\n",
    "model = build_dnn_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b9c36-5ae5-487d-91c7-74e8a77a6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model, show_shapes=False, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7709f-3167-4f8d-90e1-2a144560cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_df,\n",
    "    validation_data=test_df,\n",
    "    epochs=NUM_EVALS,\n",
    "    steps_per_epoch=steps_per_epoch#,\n",
    "    #callbacks=[tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525935b-3488-469a-a5a2-827a21c57a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "for idx, key in enumerate([\"loss\", \"rmse\"]):\n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history[\"val_{}\".format(key)])\n",
    "    plt.title(\"model {}\".format(key))\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1e130-1bfe-4ad4-96bd-ab4d3ff5b8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
